FROM python:3.10-slim

WORKDIR /app

# Copy requirements file
COPY frontend-requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir -r frontend-requirements.txt

# Copy the Gradio application
COPY gradio_app.py .

# Set environment variables with defaults
ENV API_URL=http://backend:8000
ENV OLLAMA_HOST=http://ollama:11434

# Install Ollama models during build (this will be cached in the Docker image)
RUN python -c "from langchain_community.llms.ollama import Ollama; Ollama(model='llama3', base_url='${OLLAMA_HOST}')"

# Run the Gradio app
CMD ["python", "gradio_app.py"]